{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Label Encoding vs One-Hot Encoding\n",
    "# Task: Show the difference between Label Encoding and One-Hot Encoding on the Titanic dataset for the 'Sex' feature.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 6: Combining Feature Scaling Techniques\n",
    "# Task: Demonstrate combining Min-Max Scaling and Standardization for the same datasetand explain the results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 7: Handling Multiple Categorical Features\n",
    "# Task: Handle multiple categorical features ('Sex', 'Embarked') from the Titanic dataset using One-Hot Encoding.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 8: Ordinal Encoding for Ranked Categories\n",
    "# Task: Ordinal encode 'Pclass' (Passenger class) from the Titanic dataset considering passenger class as a ranked feature.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 9: Impact of Scaling on Different Algorithms\n",
    "# Task: Investigate the impact of different scaling techniques on a decision tree model and compare it with a SVM.\n",
    "\n",
    "\n",
    "\n",
    "# Question 10: Custom Transformations for Categorical Features\n",
    "# Task: Implement a custom transformation function for encoding high cardinality categorical features efficiently.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Sample ===\n",
      "      sex embarked  pclass   age     fare\n",
      "0    male        S       3  22.0   7.2500\n",
      "1  female        C       1  38.0  71.2833\n",
      "2  female        S       3  26.0   7.9250\n",
      "3  female        S       1  35.0  53.1000\n",
      "4    male        S       3  35.0   8.0500\n",
      "\n",
      "--- Question 5 ---\n",
      "Label Encoded 'sex':\n",
      "      sex  sex_label_encoded\n",
      "0    male                  1\n",
      "1  female                  0\n",
      "2  female                  0\n",
      "3  female                  0\n",
      "4    male                  1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(X[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex_label_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# One-Hot Encoding 'sex'\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m ohe \u001b[38;5;241m=\u001b[39m \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m sex_ohe \u001b[38;5;241m=\u001b[39m ohe\u001b[38;5;241m.\u001b[39mfit_transform(X[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     37\u001b[0m sex_ohe_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(sex_ohe, columns\u001b[38;5;241m=\u001b[39mohe\u001b[38;5;241m.\u001b[39mget_feature_names_out([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load Titanic dataset from seaborn\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# Keep only relevant columns and drop rows with missing 'embarked' for simplicity\n",
    "data = titanic[['sex', 'embarked', 'pclass', 'age', 'fare', 'survived']].dropna()\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('survived', axis=1)\n",
    "y = data['survived']\n",
    "\n",
    "print(\"=== Dataset Sample ===\")\n",
    "print(X.head())\n",
    "\n",
    "# === Question 5: Label Encoding vs One-Hot Encoding on 'sex' feature ===\n",
    "print(\"\\n--- Question 5 ---\")\n",
    "\n",
    "# Label Encoding 'sex'\n",
    "le = LabelEncoder()\n",
    "X['sex_label_encoded'] = le.fit_transform(X['sex'])\n",
    "print(\"Label Encoded 'sex':\")\n",
    "print(X[['sex', 'sex_label_encoded']].head())\n",
    "\n",
    "# One-Hot Encoding 'sex'\n",
    "ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "sex_ohe = ohe.fit_transform(X[['sex']])\n",
    "sex_ohe_df = pd.DataFrame(sex_ohe, columns=ohe.get_feature_names_out(['sex']))\n",
    "print(\"One-Hot Encoded 'sex':\")\n",
    "print(sex_ohe_df.head())\n",
    "\n",
    "# === Question 6: Combining Min-Max Scaling and Standardization ===\n",
    "print(\"\\n--- Question 6 ---\")\n",
    "\n",
    "num_features = ['age', 'fare']\n",
    "scaler_minmax = MinMaxScaler()\n",
    "scaler_standard = StandardScaler()\n",
    "\n",
    "age_fare_minmax = scaler_minmax.fit_transform(X[num_features])\n",
    "age_fare_standard = scaler_standard.fit_transform(X[num_features])\n",
    "\n",
    "print(\"Min-Max scaled 'age' and 'fare' (first 5 rows):\")\n",
    "print(age_fare_minmax[:5])\n",
    "print(\"Standardized 'age' and 'fare' (first 5 rows):\")\n",
    "print(age_fare_standard[:5])\n",
    "\n",
    "# Explanation:\n",
    "print(\"\\nMin-Max scaling rescales features between 0 and 1, useful for bounded data.\")\n",
    "print(\"Standardization centers data to mean=0 and scales to unit variance, useful when data has outliers or varying scales.\")\n",
    "\n",
    "# === Question 7: One-Hot Encoding multiple categorical features ===\n",
    "print(\"\\n--- Question 7 ---\")\n",
    "\n",
    "cat_features = ['sex', 'embarked']\n",
    "ohe_multi = OneHotEncoder(drop='first', sparse=False)\n",
    "cat_encoded = ohe_multi.fit_transform(X[cat_features])\n",
    "cat_encoded_df = pd.DataFrame(cat_encoded, columns=ohe_multi.get_feature_names_out(cat_features))\n",
    "print(cat_encoded_df.head())\n",
    "\n",
    "# === Question 8: Ordinal Encoding for 'pclass' ===\n",
    "print(\"\\n--- Question 8 ---\")\n",
    "\n",
    "# Passenger class is ranked: 1 (first) > 2 (second) > 3 (third)\n",
    "ordinal_enc = OrdinalEncoder(categories=[[1, 2, 3]])\n",
    "X['pclass_ordinal'] = ordinal_enc.fit_transform(X[['pclass']])\n",
    "print(X[['pclass', 'pclass_ordinal']].head())\n",
    "\n",
    "# === Question 9: Impact of Scaling on Decision Tree vs SVM ===\n",
    "print(\"\\n--- Question 9 ---\")\n",
    "\n",
    "# Prepare dataset for modeling\n",
    "X_model = X.copy()\n",
    "\n",
    "# For simplicity, encode categorical variables using one-hot (sex, embarked) and ordinal (pclass)\n",
    "X_model = X_model.drop(['sex'], axis=1)  # drop original sex column\n",
    "X_model = pd.concat([X_model, cat_encoded_df], axis=1)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_model, y, random_state=42, test_size=0.3)\n",
    "\n",
    "# Decision Tree - no scaling required\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "print(f\"Decision Tree accuracy: {accuracy_score(y_test, dt_pred):.4f}\")\n",
    "\n",
    "# SVM without scaling\n",
    "svm = SVC(random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "print(f\"SVM accuracy without scaling: {accuracy_score(y_test, svm_pred):.4f}\")\n",
    "\n",
    "# SVM with scaling (standardization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "svm_scaled = SVC(random_state=42)\n",
    "svm_scaled.fit(X_train_scaled, y_train)\n",
    "svm_scaled_pred = svm_scaled.predict(X_test_scaled)\n",
    "print(f\"SVM accuracy with Standard Scaling: {accuracy_score(y_test, svm_scaled_pred):.4f}\")\n",
    "\n",
    "# === Question 10: Custom Transformer for High Cardinality Features ===\n",
    "print(\"\\n--- Question 10 ---\")\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TopCategoryEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encode categorical feature by keeping top N categories, \n",
    "    grouping others as 'Other' to reduce cardinality.\n",
    "    \"\"\"\n",
    "    def __init__(self, top_n=3):\n",
    "        self.top_n = top_n\n",
    "        self.top_categories_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.iloc[:, 0]\n",
    "        self.top_categories_ = X.value_counts().nlargest(self.top_n).index.tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.iloc[:, 0]\n",
    "        X_new = X.apply(lambda x: x if x in self.top_categories_ else 'Other')\n",
    "        return pd.DataFrame(X_new)\n",
    "\n",
    "# Example usage with 'embarked' column\n",
    "top_encoder = TopCategoryEncoder(top_n=2)\n",
    "top_encoder.fit(X[['embarked']])\n",
    "X_embarked_reduced = top_encoder.transform(X[['embarked']])\n",
    "print(\"Original 'embarked' categories:\")\n",
    "print(X['embarked'].value_counts())\n",
    "print(\"\\nAfter TopCategoryEncoder (top 2 kept, others grouped as 'Other'):\")\n",
    "print(X_embarked_reduced['embarked'].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
