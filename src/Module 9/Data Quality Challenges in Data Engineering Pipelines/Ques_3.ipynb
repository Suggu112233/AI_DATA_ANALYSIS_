{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Management for Data Quality\n",
    "**Description**: Store and use metadata to manage data quality in a pipeline.\n",
    "\n",
    "**Steps**:\n",
    "1. Load metadata\n",
    "2. Load data\n",
    "3. Use metadata to validate data quality\n",
    "4. Show valid data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Metadata:\n",
      "  column_name expected_dtype  allow_null  min_value  max_value\n",
      "0          id            int       False        NaN        NaN\n",
      "1        name            str       False        NaN        NaN\n",
      "2         age            int        True        0.0      120.0\n",
      "3      salary          float        True        0.0        NaN\n",
      "4  department            str        True        NaN        NaN \n",
      "\n",
      "ðŸ“Š Raw Data:\n",
      "   id     name    age   salary   department\n",
      "0   1    Alice   30.0  70000.0           HR\n",
      "1   2      Bob   25.0  55000.0  Engineering\n",
      "2   3  Charlie  150.0  60000.0        Sales\n",
      "3   4    David    NaN  40000.0          NaN\n",
      "4   5      Eve   29.0      NaN    Marketing\n",
      "5   6      NaN   40.0  50000.0           HR \n",
      "\n",
      " Column 'name' contains null values where not allowed\n",
      "\n",
      " Valid rows after metadata-based validation:\n",
      "   id   name   age   salary   department\n",
      "0   1  Alice  30.0  70000.0           HR\n",
      "1   2    Bob  25.0  55000.0  Engineering\n",
      "3   4  David   NaN  40000.0          NaN\n",
      "4   5    Eve  29.0      NaN    Marketing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# -----------------------\n",
    "# Step 0: Manually create CSV files if not present\n",
    "# -----------------------\n",
    "if not os.path.exists(\"metadata.csv\"):\n",
    "    metadata_csv = \"\"\"\\\n",
    "column_name,expected_dtype,allow_null,min_value,max_value\n",
    "id,int,False,,\n",
    "name,str,False,,\n",
    "age,int,True,0,120\n",
    "salary,float,True,0,\n",
    "department,str,True,,\n",
    "\"\"\"\n",
    "    with open(\"metadata.csv\", \"w\") as f:\n",
    "        f.write(metadata_csv)\n",
    "\n",
    "if not os.path.exists(\"data.csv\"):\n",
    "    data_csv = \"\"\"\\\n",
    "id,name,age,salary,department\n",
    "1,Alice,30,70000,HR\n",
    "2,Bob,25,55000,Engineering\n",
    "3,Charlie,150,60000,Sales\n",
    "4,David,,40000,\n",
    "5,Eve,29,,Marketing\n",
    "6,,40,50000,HR\n",
    "\"\"\"\n",
    "    with open(\"data.csv\", \"w\") as f:\n",
    "        f.write(data_csv)\n",
    "\n",
    "# -----------------------\n",
    "# Step 1: Load metadata\n",
    "# -----------------------\n",
    "metadata = pd.read_csv(\"metadata.csv\")\n",
    "print(\"ðŸ“‹ Metadata:\")\n",
    "print(metadata, \"\\n\")\n",
    "\n",
    "# -----------------------\n",
    "# Step 2: Load data\n",
    "# -----------------------\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "print(\"ðŸ“Š Raw Data:\")\n",
    "print(data, \"\\n\")\n",
    "\n",
    "# -----------------------\n",
    "# Step 3: Use metadata to validate data quality\n",
    "# -----------------------\n",
    "valid_mask = pd.Series(True, index=data.index)\n",
    "\n",
    "for _, row in metadata.iterrows():\n",
    "    col = row['column_name']\n",
    "    expected_dtype = row['expected_dtype']\n",
    "    allow_null = row['allow_null']\n",
    "    min_val = row['min_value']\n",
    "    max_val = row['max_value']\n",
    "\n",
    "    # Check if column exists\n",
    "    if col not in data.columns:\n",
    "        print(f\" Column '{col}' missing from data\")\n",
    "        valid_mask &= False\n",
    "        continue\n",
    "\n",
    "    # Check for nulls if not allowed\n",
    "    if not allow_null:\n",
    "        nulls = data[col].isnull()\n",
    "        if nulls.any():\n",
    "            print(f\" Column '{col}' contains null values where not allowed\")\n",
    "            valid_mask &= ~nulls  # Mark rows with nulls as invalid\n",
    "\n",
    "    # Check data types (basic check)\n",
    "    if expected_dtype == 'int':\n",
    "        # Try convert to numeric int, invalid conversion results in NaN\n",
    "        converted = pd.to_numeric(data[col], errors='coerce').dropna()\n",
    "        valid_rows = data[col].isin(converted) | data[col].isnull()\n",
    "        if not valid_rows.all():\n",
    "            print(f\" Column '{col}' has invalid int values\")\n",
    "            valid_mask &= valid_rows\n",
    "    elif expected_dtype == 'float':\n",
    "        converted = pd.to_numeric(data[col], errors='coerce').dropna()\n",
    "        valid_rows = data[col].isin(converted) | data[col].isnull()\n",
    "        if not valid_rows.all():\n",
    "            print(f\" Column '{col}' has invalid float values\")\n",
    "            valid_mask &= valid_rows\n",
    "    elif expected_dtype == 'str':\n",
    "        # Check if non-null values are strings\n",
    "        non_null = data[col].dropna()\n",
    "        non_str_mask = ~non_null.apply(lambda x: isinstance(x, str))\n",
    "        if non_str_mask.any():\n",
    "            print(f\" Column '{col}' has non-string values\")\n",
    "            valid_mask &= ~non_str_mask.reindex(data.index, fill_value=False)\n",
    "\n",
    "    # Check min/max if applicable and numeric\n",
    "    if expected_dtype in ['int', 'float']:\n",
    "        if pd.notna(min_val):\n",
    "            valid_mask &= data[col].ge(float(min_val)) | data[col].isnull()\n",
    "        if pd.notna(max_val):\n",
    "            valid_mask &= data[col].le(float(max_val)) | data[col].isnull()\n",
    "\n",
    "# -----------------------\n",
    "# Step 4: Show valid data only\n",
    "# -----------------------\n",
    "print(\"\\n Valid rows after metadata-based validation:\")\n",
    "print(data[valid_mask])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
