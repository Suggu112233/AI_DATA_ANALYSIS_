{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Profiling to Understand Data Quality\n",
    "**Description**: Use basic statistical methods to profile a dataset and identify potential quality issues.\n",
    "\n",
    "**Steps**:\n",
    "1. Load the dataset using pandas in Python.\n",
    "2. Understand the data by checking its basic statistics.\n",
    "3. Identify null values.\n",
    "4. Check unique values for categorical columns.\n",
    "5. Review outliers using box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "# For demonstration, we'll use the Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# Step 2: Basic statistics\n",
    "print(\"üîç Basic Statistics:\")\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# Step 3: Identify null values\n",
    "print(\"\\n‚ùó Null Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Step 4: Unique values for categorical columns\n",
    "print(\"\\nüî¢ Unique Values in Categorical Columns:\")\n",
    "categorical_cols = df.select_dtypes(include='object').columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "\n",
    "# Step 5: Review outliers using box plots for numerical columns\n",
    "print(\"\\nüì¶ Box Plots for Outlier Detection:\")\n",
    "numerical_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Box Plot of {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Implement Simple Data Validation\n",
    "**Description**: Write a Python script to validate the data types and constraints of each column in a dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Define constraints for each column.\n",
    "2. Validate each column based on its constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load dataset (using Titanic dataset for demonstration)\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
    "\n",
    "# Step 2: Define constraints\n",
    "constraints = {\n",
    "    'PassengerId': {'type': 'int', 'min': 1},\n",
    "    'Age': {'type': 'float', 'min': 0, 'max': 100},\n",
    "    'Fare': {'type': 'float', 'min': 0},\n",
    "    'Pclass': {'type': 'int', 'allowed': [1, 2, 3]},\n",
    "    'Sex': {'type': 'object', 'allowed': ['male', 'female']},\n",
    "    'Survived': {'type': 'int', 'allowed': [0, 1]}\n",
    "}\n",
    "\n",
    "# Step 3: Validate columns\n",
    "def validate_column(name, rules):\n",
    "    if name not in df.columns:\n",
    "        print(f\" Column '{name}' is missing.\")\n",
    "        return\n",
    "\n",
    "    series = df[name]\n",
    "\n",
    "    # Check type\n",
    "    actual_dtype = str(series.dtype)\n",
    "    expected_type = rules['type']\n",
    "    if expected_type == 'int' and not pd.api.types.is_integer_dtype(series):\n",
    "        print(f\" {name}: Expected integer but found {actual_dtype}\")\n",
    "    elif expected_type == 'float' and not pd.api.types.is_float_dtype(series):\n",
    "        print(f\" {name}: Expected float but found {actual_dtype}\")\n",
    "    elif expected_type == 'object' and not pd.api.types.is_object_dtype(series):\n",
    "        print(f\" {name}: Expected object/string but found {actual_dtype}\")\n",
    "    \n",
    "    # Check min/max\n",
    "    if 'min' in rules:\n",
    "        if (series < rules['min']).any():\n",
    "            print(f\" {name}: Contains values below minimum {rules['min']}\")\n",
    "    \n",
    "    if 'max' in rules:\n",
    "        if (series > rules['max']).any():\n",
    "            print(f\" {name}: Contains values above maximum {rules['max']}\")\n",
    "    \n",
    "    # Check allowed values\n",
    "    if 'allowed' in rules:\n",
    "        invalid_values = ~series.isin(rules['allowed'])\n",
    "        if invalid_values.any():\n",
    "            print(f\" {name}: Contains values not in allowed set {rules['allowed']}\")\n",
    "\n",
    "# Step 4: Run validations\n",
    "for column, rule in constraints.items():\n",
    "    validate_column(column, rule)\n",
    "\n",
    "print(\"\\n Validation Complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Detect Missing Data Patterns\n",
    "**Description**: Analyze and visualize missing data patterns in a dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Visualize missing data using a heatmap.\n",
    "2. Identify patterns in missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"your_dataset.csv\")\n",
    "\n",
    "# Plot missing values heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title(\"Missing Data Heatmap\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Integrate Automated Data Quality Checks\n",
    "**Description**: Integrate automated data quality checks using the Great Expectations library for a dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Install and initialize Great Expectations.\n",
    "2. Set up Great Expectations.\n",
    "3. Add further checks and validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here\n",
    "# Step 1: Install Great Expectations (Run once in your terminal)\n",
    "# pip install great_expectations\n",
    "\n",
    "# Step 2: Import Libraries\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "from great_expectations.dataset import PandasDataset\n",
    "\n",
    "# Step 3: Load Your Dataset\n",
    "df = pd.read_csv(\"your_dataset.csv\")  # Replace with your actual file path\n",
    "\n",
    "# Step 4: Wrap the DataFrame with Great Expectations\n",
    "ge_df = ge.dataset.PandasDataset(df)\n",
    "\n",
    "# Step 5: Add Expectations (Data Quality Checks)\n",
    "\n",
    "# Example 1: Expect no missing values in a key column\n",
    "ge_df.expect_column_values_to_not_be_null(\"column_name_1\")\n",
    "\n",
    "# Example 2: Expect age to be between 0 and 120\n",
    "ge_df.expect_column_values_to_be_between(\"age\", min_value=0, max_value=120)\n",
    "\n",
    "# Example 3: Expect a column to only have certain values\n",
    "ge_df.expect_column_values_to_be_in_set(\"gender\", [\"Male\", \"Female\", \"Other\"])\n",
    "\n",
    "# Example 4: Expect column to have unique values (e.g., IDs)\n",
    "ge_df.expect_column_values_to_be_unique(\"user_id\")\n",
    "\n",
    "# Example 5: Expect column to not be empty\n",
    "ge_df.expect_column_to_exist(\"email\")\n",
    "\n",
    "# Step 6: Validate and Get Results\n",
    "results = ge_df.validate()\n",
    "\n",
    "# Step 7: Print Validation Summary\n",
    "import json\n",
    "print(json.dumps(results, indent=2))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
