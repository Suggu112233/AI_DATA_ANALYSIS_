{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating with Apache Airflow\n",
    "**Description**: Integrate Great Expectations with Apache Airflow to run data quality checks automatically in your DAG.\n",
    "\n",
    "**Steps**:\n",
    "1. Install Airflow (if you haven't already):\n",
    "2. Airflow DAG Integration:\n",
    "    - Create a DAG file:\n",
    "3. Deploy and Test:\n",
    "    - Place this file in your Airflow DAGs directory and start your Airflow scheduler.\n",
    "    - Open the Airflow UI and trigger the DAG to see it run your expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/tmp/ipykernel_7402/3227997990.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">4</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> DeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: The `airflow.operators.python.PythonOperator` class is deprecated. Please use `</span><span style=\"color: #808000; text-decoration-color: #808000\">'airflow.providers.standard.operators.python.PythonOperator'</span><span style=\"color: #808000; text-decoration-color: #808000\">`.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/tmp/ipykernel_7402/\u001b[0m\u001b[1;33m3227997990.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m4\u001b[0m\u001b[1;33m DeprecationWarning\u001b[0m\u001b[33m: The `airflow.operators.python.PythonOperator` class is deprecated. Please use `\u001b[0m\u001b[33m'airflow.providers.standard.operators.python.PythonOperator'\u001b[0m\u001b[33m`.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "DAG.__init__() got an unexpected keyword argument 'schedule_interval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Quality Check Failed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m default_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mowner\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mairflow\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepends_on_past\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretry_delay\u001b[39m\u001b[38;5;124m'\u001b[39m: timedelta(minutes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),\n\u001b[1;32m     40\u001b[0m }\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mDAG\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgreat_expectations_data_quality\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRun Great Expectations data quality checks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschedule_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimedelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatchup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m dag:\n\u001b[1;32m     50\u001b[0m     run_quality_checks \u001b[38;5;241m=\u001b[39m PythonOperator(\n\u001b[1;32m     51\u001b[0m         task_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_data_quality_checks\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     52\u001b[0m         python_callable\u001b[38;5;241m=\u001b[39mrun_data_quality_checks,\n\u001b[1;32m     53\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: DAG.__init__() got an unexpected keyword argument 'schedule_interval'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "import great_expectations as ge\n",
    "\n",
    "def run_data_quality_checks():\n",
    "    # Initialize Great Expectations DataContext\n",
    "    context = ge.data_context.DataContext()\n",
    "\n",
    "    # Define your checkpoint name created in GE (replace with your checkpoint)\n",
    "    checkpoint_name = \"your_checkpoint_name\"\n",
    "\n",
    "    # Optionally define a batch request, if needed by your checkpoint\n",
    "    batch_request = {\n",
    "        \"datasource_name\": \"your_datasource_name\",\n",
    "        \"data_connector_name\": \"your_data_connector\",\n",
    "        \"data_asset_name\": \"your_data_asset_name\",\n",
    "        \"limit\": 1000,  # Optional limit on rows\n",
    "    }\n",
    "\n",
    "    # Run checkpoint with batch request\n",
    "    checkpoint_result = context.run_checkpoint(\n",
    "        checkpoint_name=checkpoint_name,\n",
    "        batch_request=batch_request,\n",
    "    )\n",
    "\n",
    "    # Check if validation succeeded\n",
    "    if not checkpoint_result[\"success\"]:\n",
    "        raise ValueError(\"Data Quality Check Failed!\")\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'email_on_failure': False,\n",
    "    'start_date': datetime(2025, 1, 1),\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "with DAG(\n",
    "    'great_expectations_data_quality',\n",
    "    default_args=default_args,\n",
    "    description='Run Great Expectations data quality checks',\n",
    "    schedule_interval=timedelta(days=1),\n",
    "    catchup=False,\n",
    ") as dag:\n",
    "\n",
    "    run_quality_checks = PythonOperator(\n",
    "        task_id='run_data_quality_checks',\n",
    "        python_callable=run_data_quality_checks,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
