{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Automated Data Profiling\n",
    "\n",
    "**Steps**:\n",
    "1. Using Pandas-Profiling\n",
    "    - Generate a profile report for an existing CSV file.\n",
    "    - Customize the profile report to include correlations.\n",
    "    - Profile a specific subset of columns.\n",
    "2. Using Great Expectations\n",
    "    - Create a basic expectation suite for your data.\n",
    "    - Validate data against an expectation suite.\n",
    "    - Add multiple expectations to a suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticImportError",
     "evalue": "`BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.11/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/import-error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPydanticImportError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Write your code from here\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 1. Load CSV file\u001b[39;00m\n\u001b[1;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Replace with your CSV path\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas_profiling/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Main module of pandas-profiling.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m.. include:: ../../README.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompare_reports\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compare\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontroller\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pandas_decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprofile_report\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas_profiling/compare_reports.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, List, Optional, Tuple, Union\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Correlation, Settings\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malerts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Alert\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprofile_report\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas_profiling/config.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Tuple, Union\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, BaseSettings, Field, PrivateAttr\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_merge_dictionaries\u001b[39m(dict1: \u001b[38;5;28mdict\u001b[39m, dict2: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Recursive merge dictionaries.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    :return: Merged dictionary\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/__init__.py:426\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m    424\u001b[0m dynamic_attr \u001b[38;5;241m=\u001b[39m _dynamic_imports\u001b[38;5;241m.\u001b[39mget(attr_name)\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_getattr_migration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m package, module_name \u001b[38;5;241m=\u001b[39m dynamic_attr\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__module__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/_migration.py:296\u001b[0m, in \u001b[0;36mgetattr_migration.<locals>.wrapper\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m import_string(REDIRECT_TO_V1[import_path])\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m import_path \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpydantic:BaseSettings\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticImportError(\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`BaseSettings` has been moved to the `pydantic-settings` package. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://docs.pydantic.dev/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion_short()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/migration/#basesettings-has-moved-to-pydantic-settings \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor more details.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    300\u001b[0m     )\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m import_path \u001b[38;5;129;01min\u001b[39;00m REMOVED_IN_V2:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticImportError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimport_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` has been removed in V2.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mPydanticImportError\u001b[0m: `BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.11/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/import-error"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# 1. Load CSV file\n",
    "df = pd.read_csv(\"your_data.csv\")  # Replace with your CSV path\n",
    "\n",
    "# 2. Generate full profile report with correlations\n",
    "profile = ProfileReport(\n",
    "    df, \n",
    "    title=\"Data Profiling Report\", \n",
    "    correlations={\n",
    "        \"pearson\": {\"calculate\": True},\n",
    "        \"spearman\": {\"calculate\": True},\n",
    "        \"kendall\": {\"calculate\": True},\n",
    "        \"phi_k\": {\"calculate\": True},\n",
    "        \"cramers\": {\"calculate\": True},\n",
    "    }\n",
    ")\n",
    "\n",
    "# 3. Save the report as an HTML file\n",
    "profile.to_file(\"full_profile_report.html\")\n",
    "\n",
    "# 4. Profile a specific subset of columns\n",
    "subset_columns = ['Age', 'Income', 'Gender']  # Change as needed\n",
    "subset_profile = ProfileReport(df[subset_columns], title=\"Subset Profile Report\")\n",
    "subset_profile.to_file(\"subset_profile_report.html\")\n",
    "import great_expectations as ge\n",
    "\n",
    "# 1. Load dataset into GE dataframe\n",
    "ge_df = ge.from_pandas(df)\n",
    "\n",
    "# 2. Create a new expectation suite\n",
    "suite_name = \"basic_suite\"\n",
    "context = ge.get_context()\n",
    "\n",
    "# Create an empty expectation suite\n",
    "suite = context.create_expectation_suite(suite_name, overwrite_existing=True)\n",
    "\n",
    "# 3. Add multiple expectations\n",
    "ge_df.expect_column_values_to_not_be_null(\"Age\")\n",
    "ge_df.expect_column_values_to_be_between(\"Age\", min_value=0, max_value=120)\n",
    "ge_df.expect_column_values_to_not_be_null(\"Income\")\n",
    "ge_df.expect_column_values_to_be_between(\"Income\", min_value=0)\n",
    "ge_df.expect_column_values_to_be_in_set(\"Gender\", [\"Male\", \"Female\", \"Other\"])\n",
    "\n",
    "# 4. Validate the dataset against the expectation suite\n",
    "validation_results = ge_df.validate(expectation_suite=suite_name)\n",
    "\n",
    "print(validation_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Real-time Monitoring of Data Quality\n",
    "\n",
    "**Steps**:\n",
    "1. Setting up Alerts for Quality Drops\n",
    "    - Use the logging library to set up a basic alert on failed expectations.\n",
    "    - Implementing alerts using email notifications.\n",
    "    - Using a dashboard like Grafana for visual alerts.\n",
    "        - Note: Example assumes integration with a monitoring system\n",
    "        - Alert setup would involve creating a data source and alert rule in Grafana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "import great_expectations as ge\n",
    "import logging\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='data_quality.log', \n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "def send_email_alert(subject, body, to_email):\n",
    "    # Setup your email credentials & SMTP server here\n",
    "    smtp_server = \"smtp.gmail.com\"\n",
    "    smtp_port = 587\n",
    "    sender_email = \"your_email@gmail.com\"\n",
    "    sender_password = \"your_password\"\n",
    "\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(body)\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = to_email\n",
    "\n",
    "    try:\n",
    "        with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, sender_password)\n",
    "            server.send_message(msg)\n",
    "        logging.info(f\"Alert email sent to {to_email}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to send alert email: {e}\")\n",
    "\n",
    "def check_data_quality_and_alert(df):\n",
    "    ge_df = ge.from_pandas(df)\n",
    "    suite_name = \"real_time_suite\"\n",
    "    context = ge.get_context()\n",
    "    suite = context.create_expectation_suite(suite_name, overwrite_existing=True)\n",
    "    \n",
    "    # Add expectations\n",
    "    ge_df.expect_column_values_to_not_be_null(\"Age\")\n",
    "    ge_df.expect_column_values_to_be_between(\"Age\", min_value=0, max_value=120)\n",
    "    \n",
    "    # Validate\n",
    "    results = ge_df.validate(expectation_suite=suite_name)\n",
    "    \n",
    "    # Log results\n",
    "    if not results['success']:\n",
    "        logging.warning(\"Data quality check failed!\")\n",
    "        # Compose alert message\n",
    "        failed_expectations = [r for r in results['results'] if not r['success']]\n",
    "        alert_message = f\"Data Quality Alert! Failed Expectations:\\n{failed_expectations}\"\n",
    "        send_email_alert(\"Data Quality Alert\", alert_message, \"recipient@example.com\")\n",
    "    else:\n",
    "        logging.info(\"Data quality check passed.\")\n",
    "\n",
    "# Example usage with a sample DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Age\": [25, 30, None, 150]  # Contains missing and out-of-range values\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "check_data_quality_and_alert(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Using AI for Data Quality Monitoring\n",
    "**Steps**:\n",
    "1. Basic AI Models for Monitoring\n",
    "    - Train a simple anomaly detection model using Isolation Forest.\n",
    "    - Use a simple custom function based AI logic for outlier detection.\n",
    "    - Creating a monitoring function that utilizes a pre-trained machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Step 1: Prepare sample training data with possible anomalies\n",
    "data = {\n",
    "    \"Age\": [25, 30, 35, 40, 45, 150],       # 150 is an outlier\n",
    "    \"Income\": [50000, 60000, 75000, 80000, 100000, 10]  # 10 is an outlier\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Train Isolation Forest model\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "iso_forest.fit(df)\n",
    "\n",
    "# Predict anomalies in training data\n",
    "df['anomaly'] = iso_forest.predict(df)\n",
    "print(\"Training Data with Anomaly Flags (-1 = Anomaly, 1 = Normal):\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Step 3: Define a reusable anomaly detection function\n",
    "def simple_ai_outlier_detection(dataframe, contamination=0.1):\n",
    "    model = IsolationForest(contamination=contamination, random_state=42)\n",
    "    model.fit(dataframe)\n",
    "    preds = model.predict(dataframe)\n",
    "    dataframe['anomaly'] = preds\n",
    "    outliers = dataframe[dataframe['anomaly'] == -1]\n",
    "    return outliers\n",
    "\n",
    "# Step 4: Define a monitoring function to detect anomalies in new data\n",
    "def monitor_data_quality(new_data, model):\n",
    "    preds = model.predict(new_data)\n",
    "    new_data = new_data.copy()\n",
    "    new_data['anomaly'] = preds\n",
    "    anomalies = new_data[new_data['anomaly'] == -1]\n",
    "    if not anomalies.empty:\n",
    "        print(\"Anomalies detected in new data:\")\n",
    "        print(anomalies)\n",
    "    else:\n",
    "        print(\"No anomalies detected in new data.\")\n",
    "    return anomalies\n",
    "\n",
    "# Step 5: Example new incoming data batch for monitoring\n",
    "new_data = pd.DataFrame({\n",
    "    \"Age\": [28, 33, 200],       # 200 is likely anomaly\n",
    "    \"Income\": [52000, 61000, 15]  # 15 is likely anomaly\n",
    "})\n",
    "\n",
    "# Step 6: Use the monitoring function with the trained model\n",
    "detected_anomalies = monitor_data_quality(new_data, iso_forest)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
